# tts-emotion

OVERVIEW

A common problem with AI voiceovers involves its lack of realism, especially in the aspects of emotion and tone. This project attempts to improve the functionality of text-to-speech (TTS) of AI voices through finetuning existing TTS models to better incorporate human emotion, creating a more realistic and immersive AI audio experience.


PREREQUISITES

Refer to requirement.txt for the full list of prerequisites needed to run the model.


HOW TO USE


FILE FORMAT

The file consists of frontend.html, which is the user interface for the TTS model. By inputting text, an AI generated speech is output, incorporating human emotion into its speech. googlecloud.py makes use of the Google AI  



DATASET

The dataset used can be generated by running the code below using Python.

from google.colab import files

!zip -q -r dataset.zip /tmp/xtts_ft/dataset

files.download('dataset.zip')

MODELS USED

[TTS by Coqui AI] (https://github.com/coqui-ai/TTS)
https://www.gradio.app
